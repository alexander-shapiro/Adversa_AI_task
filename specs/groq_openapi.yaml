openapi: 3.1.0
info:
  title: Groq API
  version: 1.0.0
  description: The Groq API for fast LLM inference.

servers:
  - url: https://api.groq.com/openai/v1

security:
  - BearerAuth: []

components:
  securitySchemes:
    BearerAuth:
      type: http
      scheme: bearer
      description: "Use 'Bearer YOUR_API_KEY' in the Authorization header"

  schemas:
    ChatCompletionRequest:
      type: object
      required:
        - model
        - messages
      properties:
        model:
          type: string
          description: ID of the model to use
          example: llama-3.1-70b-versatile
        messages:
          type: array
          description: A list of messages comprising the conversation
          items:
            type: object
            required:
              - role
              - content
            properties:
              role:
                type: string
                enum: [system, user, assistant]
              content:
                type: string
        max_tokens:
          type: integer
          description: Maximum number of tokens to generate
        temperature:
          type: number
          description: Sampling temperature
        stream:
          type: boolean
          default: false

    ChatCompletionResponse:
      type: object
      properties:
        id:
          type: string
        object:
          type: string
          example: chat.completion
        created:
          type: integer
        model:
          type: string
        choices:
          type: array
          items:
            type: object
            properties:
              index:
                type: integer
              message:
                type: object
                properties:
                  role:
                    type: string
                  content:
                    type: string
              finish_reason:
                type: string
        usage:
          type: object
          properties:
            prompt_tokens:
              type: integer
            completion_tokens:
              type: integer
            total_tokens:
              type: integer

    Error:
      type: object
      properties:
        error:
          type: object
          properties:
            message:
              type: string
            type:
              type: string

paths:
  /chat/completions:
    post:
      operationId: createChatCompletion
      summary: Creates a chat completion
      description: Generate a response using Groq's fast inference
      tags:
        - Chat
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ChatCompletionRequest'
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatCompletionResponse'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Error'

  /models:
    get:
      operationId: listModels
      summary: List available models
      tags:
        - Models
      responses:
        '200':
          description: List of models
